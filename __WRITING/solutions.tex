\chapter{Analytické úlohy nad prúdom dát}
\label{Analytické úlohy v prúde dát}
Spracovanie, analýza a dolovanie dát predstavuje vo všeobecnosti výzvu. Zvláštnu pozornosť si tieto úlohy vyžadujú pri spracovaní, analýze a dolovaní z prúdu prúdu udalostí. Prúd udalostí je často nazývaný \textit{prúd dát} alebo \textit{údajov}, či len skrátene \textit{prúd}. V tomto texte budeme pre jednoduchosť používať najmä termín \textit{prúd} a \textit{prúd dát} \citep{tran2014change}. Avšak môžu sa vyskytnúť aj terminý ako \textit{prúd udalostí}, \textit{sekvencia udalostí, či elementov}, pričom všetky termíny majú v tomto texte \textit{rovnaký} význam. \par
\begin{definition}{Prúd je potenciálne nekonečná sekvencia elementov \citep{tran2014change}.}
\begin{align*}
	S = \{(X_1,T_1), ..., (X_j,T_j), ...\}
\end{align*}
Kde každý element je pár $(X_j,T_j)$ kde $X_j$ je d-dimenzionálny vektor $X_j = (x_1, x_2, ..., x_d)$ prichádzajúci v čase $T_j$. $T_j$ je často nazývaný aj časová pečiatka, existujú dva typy časovej pečiatky: explicitná je generovaná keď dáta dorazia, implicitná je priradená vektoru v čase ich vzniku.
\end{definition}

% Vseobecny popis toho preco je potrebne prudove spracovanie dat
Takmer každé odvetvie dnes generuje masívne množstvo dát. Vzhľadom na ich veľký objem analytyci a doménový experti často strácajú schopnosť dolovať v celej sade dát. Stáva sa preto častým zvykom, že sa vyberie reprezentujúca vzorka, ktorej spracovanie predstavuje menšiu časovú a pamäťovú výzvu. Pri pamäťovej náročnosti hovoríme o limitoch počítača, pričom ak hovoríme o časovej náročnosti hovoríme o limitovanom čase doménového experta (čakanie na výsledok analýzy) \citep{hulten2001mining}. Predpokladajme, že bude pre doménoveho experta vysokým prínosom možnosť vykonávať analýzy nad prúdom v reálnom čase. Výstupy z takejto analýzy sú na rôznej granularite a úrovni, pričom môžu byť neskôr použité na ďalšie spracovanie alebo na priame prezentovanie výsledkov. \par

% Vyskumne vyzvy v prudoch dat vseobecne
Analýza a spracovanie prúdov dát pridáva viaceré otvorené výzvy a možnosti pre výskum \citep{krempl2014open}:
\begin{itemize}
	\item \textit{Ochrana súkromia a dôvernosti} pri analýze a dolovaní v prúde dát. Hlavným cieľom je vyvinúť metódy a techniky, ktoré neodhalia informácie a vzory, ktoré by kompromitovali potreby dôvernosti a ochrany súkromia. Dve hlavné výzvy pri analýze a dolovaní v prúdoch dát sú: \textit{vysporiadanie sa s neúplnými dátami} a \textit{uchovanie zmien (angl. concept drift) v prúde dát}.
	\item \textit{Predspracovanie} dát je dôležitou súčasťou každej reálnej aplikácie, najmä tých pre analýzu dát. Zatiaľ čo pri tradičnej analýze dát je predspracovanie vykonané jednorázovo, zvyčajne doménovým expertom. ktorý rozumie dátam. Pri prúde dát toto nieje prijateľné, pretože dáta nepretržite prichádzajú. Okrem niekoľkých štúdií \citep{zliobaite2014adaptive, anagnostopoulos2008deciding} tejto problematike nebola venovaná dostatočná pozornosť ako pri tradičnom spracovaní dát. Hlavné výzvy, ktorým treba čeliť pri predspracovaní prúdu dát sú: \textit{hluk v dátach}, \textit{outliers} a \textit{adaptívny výber vzorky}.
	\item \textit{Načasovanie a dostupnosť informácie}, väčšina algoritmov robí jednoduchý predpoklad, že prijatá informácia je kompletná, ihneď dostupná, prijatá pasívne a zadarmo. Viaceré výzvy spojené s načasovaním a dostupnosťou informácie sú formulované a nepreskúmané: \textit{spracovanie nekompletných dát}, \textit{vysporiadanie sa so skreslenou (angl. skewed) distribúciou dát} a \textit{spracovanie oneskorených dát}.
	\item \textit{Dolovanie entít a udalostí} kde entity predstavujúce prúd sú spojené do viacerých inštancií resp. štruktúrovaných informácií (napr. agregácie). Tieto entity môžu byť niekedy spojené s výskytom udalostí resp. v prúde dát. 
	\item \textit{Evaluácia algoritmov pre prúdy dát} predstavuje úplne novú výzvu v porovnaní s tradičnými metódami. Pri evaluácií v prúde dát sa musíme vysporiadať s problémami ako: \textit{zmeny (angl. concept drift}, \textit{limitovaný čas pre spracovanie vzorky}, \textit{vyvíjajúce sa skreslenie tried dát}, či \textit{oneskorenie overenia}. Tejto problematike sa v poslednej dobe venuje vyššia pozornosť, ako napríklad pre evaluáciu klasifikátorov nad prúdmi dát \citep{bifet2015efficient}.
	\item \textit{Špecializované, reaktívne a jednoduché modely} na pochopenie pre doménového experta. Tieto tri výzvy v sebe ukrývajú potrebu pre minimalizáciu závislosti na nastavení parametrov metódy, kombinácia online a offline modelov a riešenie správného problému (zmeny v prúdoch).
\end{itemize}

% Model prudu dat
\paragraph{Model prúdu dát} môže byť jeden z nasledujúcich: model časových radov, pokladničný model a model turniketu. Podľa modelu prúdu dáť existujú príslušné algoritmy, ktoré boli vytvorené pre daný model \citep{tran2014change}. Majme prúd dát $a_1, a_2, ...$, ktorý prichádza sekvenčne za sebou a popisuje podstaný signál $A$. 
V modeli časových radov každá vzorka $a_i$ sa rovná $A[i]$ pričom vzorky prichádzajú v vzostupnom poradí. Tento model je vhodný pre prúdy dát, ktoré nesú v sebe časovú postupnosť alebo je ich poradie určované časovou pečiatkou \citep{muthukrishnan2005data}.
Pri pokladničnom modeli môžme považovať množinu $U = {1, 2, ..., n}$ za element z prúdu dát. Ak uvažujeme sekvenciu $2, 1, 2, 5$ ako príklad, potom hovoríme o pokladničnom modeli. Tento model je často používaný v praxi, napríklad v prípadoch kde sled IP adries pristupuje na Web server \citep{ikonomovska2013algorithmic, muthukrishnan2005data}.
Model turniketu je veľmi podobný pokladničnému modelu. Rozdiel je v tom, že vzorka môže predstavovať aj zápornú hodnotu - analógia z reálneho sveta kedy niektorí ľudia prichádzajú a vychádzajú turniketom, počet ľudi sa mení (napr. na zjazdovke) \citep{ikonomovska2013algorithmic, muthukrishnan2005data}.

% Predspracovanie prudu dat
\paragraph{Predspracovanie prúdu}
Predspracovanie je azda najdôležitejším krokom v aplikáciach reálneho sveta a časovo najnáročnejšou úlohou pre každého analytika. Nakoľko dáta prichádzajú z nehomogénneho sveta, môžu byť zašumené, nekompletné, duplicitné alebo často obsahovať hodnoty, ktoré sa značne líšia od ostatných. Predspracovanie prúdiach údajov je potrebné čo najviac automatizovať. Existuje niekoľko známych metód a techník, ktoré sú používané pri predspracovaní prúdov dát \citep{krempl2014open, nguyen2015survey}:
\begin{itemize}
	\item \textit{Vzorkovanie}, napríklad podľa pravdepodobnostného modelu.
	\item \textit{Zahadzovania potenciálne nepotrebných vzoriek}, ak je spracujúci proces príliš zaťažený. Tu môže nastať problém, že práve zahodená vzorka bola dôležitá (zmena v dátach).
	\item \textit{Agregácia} údajov môže značne znížiť objem dát, ale môže spôsobiť problém pri potrebe pohľadu do minulosti.
	\item \textit{Aproximačné algoritmy} a ich použitie má za následok podstatné zrýchlenie spracovania a analýzy prúdov za predpokladu istej chybovosti. Chybovosť je zvačsa ohraničená.
	\item \textit{Posuvné okno}, tento prístup vznikol s potrebou analýzy definovaného časového okna z prúdiacih údajov. Výstup je teda závislí na zvolenej veľkosti okna. Problém pri tomto prístupe je práve správne nastavenie veľkosti okna tak aby sme vedeli zohladniť zmeny v prúde dát.
\end{itemize}

\par
Pri dolovaní z prúdov dát (angl. data stream mining) je potrebné aby algoritmy splňovali nasledujúce obmedzenia \citep{nguyen2015survey, wadewale2015survey}:
\begin{itemize}
	\item Jeden priechod cez dáta (angl. single-pass). Narozdiel od tradičných metód kde je možné dáta prečítať viac krát, pretože sú dáta dostupné na disku. Pri dolovaní v prúde dát nové vzorky prichádzajú kontinálne a musíme preto každú vzorku spracovať práve raz v momente keď príde.
	\item Odpoveď v reálnom čase v zmysle, že vytvorený model je pripravený kedykoľvek (angl. anytime real-time resposne) napríklad predikovať triedy nových vzoriek.
	\item K dispozícii máme len ohraničenú pamäť. Toto obmedzenie súvisí s povahou prúdou dát a to, že prúdy predstavujú potenciálne nekonečné zdroje dát.
	\item Detekcia zmien (angl. concept-drift detection) je nevyhnutná v situácii keď sa v dátach objavia nové vzory, ktoré sa menia v čase.
\end{itemize}

% Dolovanie a extrakcia informacii
\paragraph{Spracovanie, dolovanie a analýza prúdu dát} 
Problematika spracovania, dolovania a analýzy v statickej kolekcii dát bola študovaná niekoľko dekád. Zvýšenú pozornosť začala odborná verejnosť venovať pri aplikovaní týchto úloh na prúdy dát. Niektorým z týchto úloh sa venujeme podrobne v nasledujúcich podkapitolách:
\begin{itemize}
	\item \textit{Klastrovanie}, existuje niekoľko výskumov, ktoré sa venovali špeciálne klastrovaniu implementovaním napríklad k-mediánu a inkrementálnych algoritmov.
	\item \textit{Klasifikácia}, táto úloha je dlho skúmaná s použitím rôznych metód rozhodovacích stromov.
	\item \textit{Počítanie frekvencie a opakovaní}, použitím posuvných okien a inkrementálnych algoritmov na detekciu vzorov v prúde.
	\item \textit{Analýza časových radov použitím symbolickej} reprezentácie časových radov v prúde dát. Takáto reprezentácia nám umožňuje redukciu veľkosti prenášaných dát. Táto technika pozostáva z dvoch hlavných krokov, aproximácia po častiach a následná transformácia výsledku do diskrétnych veličín.
\end{itemize}

% Evaluacia
\paragraph{Evaluácia} modelov vytvorených nad prúdmi dát je základná a dôležitá úloha pre meranie kvality modelu. Toto so sebou prináša výzvy, pretože prúdy dát sú potenciálne nekončné, evaluáciu modelov je potrebné vykonávať online zatiaľ čo dáta často vytvárajú problémy, napríklad nerovnomerné rozdelenie tried v prúde dát. Potom, tradičné techniky evaluácie známe z dávkových algoritmov pre analýzu dát, nie sú použiteľné pre evaluáciu prúdov dát. \citet{bifet2015efficient} hovoria o troch hlavných mylných prístupoch k evaluácii prúdu dát:
\begin{itemize}
	\item \textit{McNemarov test} a jeho použitie na pre štatistické rozlíšenie kvality dvoch klasifikátorov. Aj napriek štatisticky signifanktnému rozdielu medzi klasifikátormi tento test nieje vhodný pre prúdy dát, pretože aj keď je model vytvorený rovnakým algoritmom, väčšina algoritmov je inicializovaná alebo používa nejakú náhodnú zložku. To môže viesť k zavádzajúcim výsledkom pri použití tohto testu.
	\item \textit{Rozdeľovanie množiny dát} do trénovacej a testovacej množiny vedie k nemožnosti rozoznať výkonnosť rôznych klasifikátorov. Je to z dôvodu, že v dátach sa môžu objavovať napríklad zmeny, ktoré budu skreslené rozdeľovaním alebo vzorkovaním dát.
	\item \textit{Väčšina tried v posuvnom okne} môže spôsobiť pozitívne $k$ štatistiky a tiež pozitívne výsledky harmonického priemeru pre niektoré periódy prúdu dát.
\end{itemize}
\citet{bifet2015efficient} odporúčajú použitie nasledujúcich metód pre evaluáciu v kontexte prúdov dát: \textit{Najprv testuj-potom-trénuj} (angl. Test-Then-Train alebo tiež Prequential) spočíva v myšlienke, že každá vzorka z prúdu dát je použitá najprv na testovanie a potom na trénovanie modelu. Keďže modely vytvorené nad prúdmi dát by mali byť schopné poskytnúť predikcie okamžite a v reálnom čase, tento prístup by nemal výrazne ovplyvniť výkon metódy. Obmenou tohto prístupu môže byť evaluácia na nejakom posuvnom okne, ktoré môže byť vyberané napríklad algoritmom $ADWIN$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%         Dopytovanie sa v prúdoch dát          %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dopyty nad prúdom dát}
Vyhodnocovaniu dopytov nad statickou kolekciou dát bola venovaná značná pozornosť, ak však hovoríme o prúdoch dát dopyty musia byt vyhodnocované kontinuálne \citep{babu2001continuous, babcock2002models}. Vzniká teda nová paradigma pre interakciu s dynamicky sa meniacimi dátami, ktorú nazývame kontinuálne dopyty (angl. continious queries) \citep{babu2001continuous}. Výsledky kontinuálnych dopytov sú produkované dynamicky v čase vzniku nových dát. Príkladom použitia takýchto dopytov je napríklad sledovanie vývoja akcií burzy. Problém môže nastať pri jednorázových dopytoch, ktoré obsahujú agregačné funkcie. Pri tradičnom spracovaní dát kde sú všetky dáta uložené ako statická kolekcia, je dopyt vykonaný nad celou kolekciou. V prípade kontinuálneho dopytu je problém získať predchádzajúce dáta za predpokladu, že dáta niesú ukladané. Môžu potom nastať dva scenáre:
\begin{enumerate}
	\item agregačná funkcia je prepočítaná nad kolekciou dát, za predpokladu, že boli historické dáta ukladané.
	\item agregačná funkcia je počítaná od momentu zadanie dopytu.
\end{enumerate}
Kontinuálne dopytovanie do prúdu dát nesie so sebou nieľko výziev \citep{babcock2002models}:
\begin{itemize}
	\item \textit{Limitované pamäťové požiadavky} na algoritmy spracujúce dopyty, pretože prúd dát predstavuje potenciálne nekonečný prúd udalostí.
	\item \textit{Približné odpovede na dopyty} sú niekedy postačujúce za predpokladu, že odpoveď je dostatočné rýchla a používateľ rozumie v akej presnosti mu bola odpoveď poskytnutá. Techniky pre redukciu dimenzionality a objemu dát zahŕňajú napríklad: histogramy, náhodné vzorkovanie, symbolické vzorkovanie apod.
	\item \textit{Dopytovací jazyk} by mal byť podobný štandardu jazyka SQL. Jazyk SQL je známy deklaratívny jazyk, je široko používaný so zavedením štandardom, ktorý poskytuje flexibilitu a optimálnu evaluáciu dopytu a vykonanie nad prúdom, či datasetom. 
\end{itemize}
Výskumné práce sa tiež venovali adaptívnym kontinuálnym dopytom nad prúdmi dát. Bolo ukázané, že takýto prístup môže mať značný prínos v oblasti výkonnosti systému vďaka jeho schopnosti adaptácie na zmeny v prúde dát. Tieto vlastnosti sú dosiahnuté aplikovaním zoskupovania indexov filtrov na priebežný výber predikátov \citep{madden2002continuously}. \par
Ďalší priestor na zlepšenie výkonnosti kontinuálnych dopytov nad prúdmi dát predstavujú adaptívne filtre. Pri dopytovaní sa takmer vždy vykonáva filtrovanie dát v nejakej podobe. Tento krok filtrovania je obvykle implementovaný v systéme na spracovanie dopytov. Pre zvýšenie výkonnosti dopytov je preto možné tieto filtre presunúť priamo do zdrojov dát. Ukázalo sa, že takýto prístup môže mať pozitívny dopad na výkonnosť \citep{olston2003adaptive}. Tento prístup prinesie najmä redukciu prenášaných dát výmenou za ich nepresnosť. Problémom tejto techniky je, že je aplikovateľná len v prostredí, ktoré máme plne pod kontrolou a vieme zasahovať do všetkých jeho súčastí.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%               Detekcia zmien                  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Detekcia zmien}
Detekcia zmien (angl. concept drift) zohráva, v dnešnom rýchlo sa meniacom svete, dôležitú úlohu. Zmeny nastávajú veľmi rýchlo a nečakane. Preto stúpa potreba detekcie zmeny a následná správna reakcia, ktorá vyplynie z detekovanej zmeny. Na to aby sme boli schopný na tieto zmeny adekvátne reagovať je potrebné dáta spracovávať tak ako vznikajú a pozerať sa na ne ako na prúd udalostí. Tradičné metódy pre paralelné spracovanie uvažujú len statickú kolekciu dát \citep{tran2014change}. Existuje niekoľko typov zmien, ktoré môžu nastať v prúde dát \citep{wadewale2015survey}: \textit{náhla} (angl. sudden), \textit{inkrementálna}, \textit{graduálna}, \textit{opakujúca}, \textit{falošná} a \textit{šum}. Spomenuté zmeny sú zobrazené na obrázku \ref{fig:types-of-concept}.
\myFigure{images/types-of-drift}{Typy zmien (angl. concept drift) \citep{w
}.}{test-dia}{0.5}{h!}\label{fig:types-of-concept}
Detekcia zmeny predstavuje proces identifikácie zmeny aktuálneho stavu modelu voči predchádzajúcemu. Na tento objekt sa pozeráme v rôznom čase. Dôležitý rozdiel medzi zmenou a rozdielom je, že zmena hovorí o prechode modelu do iného stavu, zatiaľ čo rozdiel znamená nepodobnosť v atribútoch dvoch objektov. V kontexte prúdu, detekovanie zmeny je proces segmentácie prúdu udalostí do rôznych segmentov a identifikovanie miest kde sa zmení dynamika prúdu \citep{ross2009online}. Metóda pre detekciu zmien musí riešiť nasledujúce úlohy \citep{tran2014change}: \textit{detekcia zmeny} znamená správnu identifikáciu zmeny a \textit{lokalizácia zmeny} hovorí o identifikovaní momentu kedy zmena nastala. Týmto úloh je potrebné venovať dostatočnú pozornosť, pretože zmeny môžu byť falošné alebo dočasné čo so sebou prináša problém lokalizácie danej zmeny. Ďalší rozdiel, ktorý je potrebné zadefinovať, je medzi rozdiel detekovaním posunu pojmu (angl. concept drift). Pre lepšiu čitateľnosť tohto textu budeme pod pojmom detekcia zmeny, zmena rozumieť posun pojmu. Detekcia concept drift-u sa sústreďuje na označkované dáta, zatiaľ čo detekcia zmeny pracuje s označkovanými rovnako ako s neoznačkovanými dátami. Posun pojmu nazývame tiež časté zmeny v účelovej funkcii modelu, ktorý sa učí online. \par

Metódy pre detekovanie zmien môžme klasifikovať do nasledujúcich prístupov \citep{liu2010mining}: \textit{metódy založené na stave}, \textit{metódy sledujúce trend} a \textit{prahové metódy}. Algoritmus pre detekciu zmien by mal spĺňať aspoň nasledovné požiadavky: \textit{presnosť}, \textit{rýchlosť} a \textit{odpoveď v reálnom čase}. Algoritmus by tiež mal detekovať čo najmenej chybných zmien a čo najviac správnych presných miest zmeny. Algoritmy by mali byť prispôsobené reálnemu prostrediu a spracovaniu prúdov vysokých objemov a rýchlostí. Na obrázku \ref{fig:zmeny-vseobecny-dia} je zobrazený všeobecný diagram pre detekciu zmeny v prúde udalostí.

\myFigure{images/2_zmeny_vseobecny-diagram}{Všeobecný diagram zobrazujúci detekciu zmeny v prúde udalostí \citep{tran2014change}.}{test-dia}{0.5}{h!}\label{fig:zmeny-vseobecny-dia}

% Techniky a metody pre detekciu zmeny v prudoch
Pre detekciu zmeny v prúdoch dát bolo vyvinutých niekoľko techník a metód. Niektoré z nich nižšie podrobnejšie popisujeme.

% Charakteristika dat
\paragraph{Charakteristika dát} Metódy pre detekciu zmien môžu byť klasifikované na základe charakteru dát, s ktorými pracujú. Najčastejšie môžme prúdy klasifikovať do kategorických alebo numerických prúdov. Ak hovoríme o kategorických prúdoch, dáta obsiahnuté v prúde majú kategorický charakter, napríklad rôzny výrobcovia áut: $x \in \{Volvo, Toyota\}$. Pri numerických prúdoch dáta predstavujú numerické hodnoty $x \in {\rm I\!R}$. Pre každý takýto prúd boli vyvinuté príslušné algoritmy. Problém nastáva pri aplikáciach s dátami reálneho sveta kde prúdy často obsahujú numerické aj kategorické dáta. V takýchto situáciach má zmysel dáta rozdeliť rovnomenných skupín obsahujúce dáta rovnakého typu. Na tieto skupiny sú následne použté príslušné algoritmy. Prúdy dát sa ďalej môžu klasifikovať do označkovaných a neoznačkovaných prúdov. Neoznačkované prúdy obsahujú dáta, ktoré niesú zaradené do žiadnej triedy. Naopak označkované prúdy nesú v sebe informáciu o tom, do ktorej triedy patrí vybraný element. Rôzny charakter prúdu predstavuje rôzne zmeny a prístup na ich riešenie pri detekcii zmien v prúde \citep{tran2014change}.

% Kompletnost statistickej informacie
\paragraph{Metóda pre detekciu zmeny} V skratke DDM z anglického Drift Detection Method. Táto metóda sa zaoberá detekciou zmeny modelu. Majme prúd dát $(x_i,y_i)$ kde $x_i$ predstavuje atribúty a $y_i$ triedu vzorky. Model sa potom snaží predikovať skutočnú triedu $y_i+1$ novej vzorky. Gama a spol. založili DDM na fakte, že každá iterácia klasifikátora predikuje triedu vzorky. Klasifikátor je binárny, takže trieda môže byť len $pravda$ alebo $nepravda$. Potom, pre množinu vzoriek, chyba predstavuje náhodnú premennú z Bernoulliho pokusov (angl. Bernoulli trials). Vďaka tomu môžme chybu modelovať s bínomickým rozdelením. Nech $p$ je pravdepodobnosť zlej predikcie a $s_i$ je štandardná odchýlka vypočítaná nasledovne:
\begin{align*}
s_i = \sqrt{ \frac{p_i(1-p_i)} {i} }
\end{align*}
Pre každú vzorku z prúdu sú udržiavané dve premenné, $p_min$ a $s_min$. Ich hodnoty sú použité na výpočet varovnej hodnoty, ktorá slúži na definovanie optimálnej velkosti kontextového okna. Kontextové okno si udržiava staré vzorky, ktoré obsahujú nový kontext resp. zmenu, či posun pojmu, a minimálny počet elementov zo starého konextu. Ak sa následne zníži množstvo chybne predikovaných vzoriek, okno je zahodené ako zle identifikovaná zmena (false alarm). Naopak, ak je dosiahnutá dostatočná varovná úroveň, predtým naučený model je zahodený a vytvorený nový, ale iba zo vzoriek ktoré boli uložené do kontextového okna \citep{gama2004learning, brzezinski2010mining}.
\par
Existuje tiež rozšírenie EDDM, ktoré je modifikáciou DDM. Tento algoritmus používa rovnakú techniku varovných alarmov, ale namiesto klasifikácie chyby používa metriku množstva rozdielnych chýb. EDDM metóda dosahuje lepšie výsledky pri postupných zmenách, ale je citlivejšia na hluk v dátach \citep{wadewale2015survey}.

% ADWIN
\paragraph{ADWIN} je skratka pre algoritmus s názvom adaptívne posuvné okno (angl. adapting sliding window). Tento algoritmus je vhodný je prúdy s náhlymi zmenami. Algoritmus si udržiava okno $W$ s najnovšími vzorkami. Okno $W$ je automatický zväčšované, ak nieje detekovaná žiadna výrazná zmena v prúde a naopak zmenšované, ak bola zmena detekovaná. Obmedzenie nárastu okna do nekonečna (žiadna zmena v prúde) je možné parametrom algoritmu, ktorý bude limitovať dĺžku okna $W$. ADWIN taktiež poskytuje ohraničenie výkonu na základe množstva falošne pozitívne a falošne negatívnych vzoriek \citep{wadewale2015survey}. Základná verzia algoritmu ADWIN je vhodná pre 1-dimenzionálne dáta. Ak je potrebné detekovať zmeny pre viac-dimenzionálne dáta, potom sa vytvára paralelne niekoľko okien pre každú dimenziu dát \citep{brzezinski2010mining}.

\par
Existuje mnoho ďalších prístupov ako sa vysporiadať so zmenami v prúde, napríklad: exponenciálne váhovaný posuvný priemer, štatistické testovanie rovnomerného podielu, súborové (angl. ensemble) metódy. Popis všetkých metód je nad rámec tejto práce.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%             Detekcia anomálií                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Detekcia anomálií}
Detekcia anomálií (angl. anomaly detection) predstavuje proces identifikácie dát, ktoré sa význačne odchyľujú (angl. deviate) od historických vzorov \citep{hodge2004survey}. Anomálie môžu spôsobovať chyby v meraní senzorov, nezvyčajné správanie systému alebo chyba pri prenose dát, či zámerné vytváranie anomálií v používateľmi generovanom obsahu. 
Takže detekcia anomálií má veľa praktického použitia napríklad v aplikáciach, ktoré dohliadajú na kvalitu a kontrolu dát \citep{hill2007real} alebo adaptívne monitorovanie sietí  \citep{hill2010anomaly}. Tieto aplikácie často kladú požiadavku aby boli anomálie detekované v čase ich v vzniku, teda v reálnom čase. Potom metódy pre detekciu anomálií musia byť rýchle vo vykonávaní a mať inkrementálny charakter. \par

V minulosti sa obvykle anomálie detekovali manuálne s pomocou vizualizačných nástrojov, ktoré doménovým expertom pomáhali v tejto úlohe. Manuálne metódy avšak zlyhávajú pri detekcií anomálií v reálnom čase. Výskumníci navrhli niekoľko metód, ktoré majú myšlienku v prístupoch strojového učenia sa a automatizovaného štatistického vyhodnocovania \citep{hill2010anomaly}: \textit{minimálny objem elipsoidu}, \textit{konvexný zvon}, \textit{najbližší sused}, \textit{zhlukovanie}, \textit{klasifikácia neurónovou sieťou}, \textit{klasifikácia metódou podporných vektorov} a \textit{rozhodovacie stromy}. Tieto metódy sú pochopiteľne rýchlejšie než manuálna detekcia, avšak jeden význačný nedostatok, bez úpravy niesú vhodné pre prúdové spracovanie v reálnom čase. Existujú napríklad rozhodovacie stromy, ktoré si dokážu budovať model inkrementálne, avšak sa líšia od dobre známych algoritmov. Táto metóda je podrobne popísana ďalej v texte.

\paragraph{Dátovo riadená metóda} (angl. data-driven), ktorú navrhli \citep{hill2010anomaly}, využíva dátovo riadený jednorozmerný autoregresívny model prúdu dát a predikčný interval (ďalej len PI) vypočítaný z posledných historických dát na identifikáciu anomálií v prúde. Dátovo riadený model časového radu je použitý, pretože je jednoduchší na implementáciu a použitie v porovnaní s ostatnými modelmi časových radov. Tento model tiež poskytuje rýchle a presné prognózy. Dáta sú potom klasifikované ako anomálie na základe toho, či sú spadnú do zvoleného intervalu PI. Metóda teda poskytuje principiálny rámec pre výber hraničného prahu kedy majú byť anomálie klasifikované. Výhoda metódy je, že nevyžaduje žiadne vzorky dát, ktoré sú vopred označkované alebo klasifikované. Je veľmi dobre škálovateľná na veľké objemy dát a vykonáva inkrementálne počítanie tak ako dáta vznikajú.
Metóda pozostáva z nasledujúcich krokov so začiatkom v čase \textit{t}:
\begin{enumerate}
	\item použi model na predikciu o krok vpred (angl. one-step-ahead), ktorý má ako vstup $\displaystyle D^t = \{x_{t-q+1}, ..., x_t\}$ \textit{q} je rôzne meranie \textit{x} v čase \textit{t} a $\displaystyle D^t$ je model predikcie. Tento model je použitý ne predikovanie hodnoty $\displaystyle \overline{x}_{t+1}$ ako očakávaná hodnota v čase \textit{t+1}.
	\item výpočet hornej a spodnej hranice kam by malo spadnúť pozorované meranie s pravdepodobnosťou \textit{p}.
	\item porovnaj pozorovanie v čase \textit{t+1}, či spadá do určeného intervalu. Ak spadne mimo intervalu, objekt je klasifikovaný ako anomália.
	\item 
		\begin{enumerate}
			\item pri stratégii metódy detekcie anomálií a zmiernenia (angl. anomaly detection and mitigation) ADAM, ak je pozorovaný objekt klasifikovaný ako anomália, modifikuj $\displaystyle D^t$ odstránením $\displaystyle x_{t-q+1}$ z konca pozorovaného okna a pridaním $\displaystyle \overline{x}_{t+1}$ na začiatok okna, čím vytvoríme $\displaystyle D^{t+1}$.
			\item pri jednoduchej stratégii detekcie anomálií (angl. anomaly detection) AD, modifikuj $\displaystyle D^t$  odstránením $\displaystyle x_{t-q+1}$ z konca okna a pridaj $\displaystyle x_{t+1}$ na začiatok okna čím vznikne $\displaystyle D^{t+1}$.
		\end{enumerate}
	\item opakuj kroky \textit{1-4}
\end{enumerate}
\paragraph{Metóda dynamických bayesových sietí} (angl. Dynamic Bayesian Networks) \citep{hill2007real} bola vytvorená pre detekciu anomálií v prúdoch zo senzorov, ktoré sú umiestnené v životnom prostredí. Bayesové siete predstavujú acyklický orientovaný graf, zobrazené na obrázku \ref{fig:anomalie-dbn}, v ktorom každý uzol obsahuje pravdepodobnostú informáciu v súvislosti k všetkým možným stavom, v ktorých sa môže premenná nachádzať. Táto informácia spolu s topológiou bayesovej siete, špecifikuje úplné spojenie distribúcie stavu premennej, pričom sada známych premmených môže byť použitá na odvodenie hodnoty neznámych premenných. Dynamické bayesové siete s topológiou, ktorá sa vyvýja v čase, pridáva nové stavové premenné pre lepšiu reprezentáciu stavu systému v aktuálnom čase \textit{t}. Stavové premmné môžeme kategorizovať ako \textit{neznáme}, ktoré predstavujú skutočný stav systému a \textit{merané}, ktoré sú nedokonalé merania. Tieto premenné môžu byť naviac diskrétne alebo spojité. Nakoľko sa veľkosť siete zväčšuje s časom, vytváranie záverov použitím celej siete by bolo neefektívne a časovo náročné. Preto boli vyvinuté aproximačné algoritmy ako \textit{Kalmanové filtrovanie} alebo \textit{Rao-Blackwellized časticové filtrovanie}. \par
Hill et al. navrhli v \citep{hill2007real} dve stratégie pre detekovanie anomálií v prúde dát:
\begin{itemize}
	\item \textit{Bayesov dôveryhodný interval} (angl. Bayesian credible interval - BCI), ktorý sleduje viacrozmernú gausovskú distribúciu lineárneho stavu premennej, ktorý korešponduje s neznámym stavom systému a jej meraným náprotivkom.
	\item \textit{Maximálne posteriori meraný status} (angl. Maximum a posteriori measurement status - MAP-ms) používa komplexnejšiu dynamickú bayseovú sieť. Princíp je rovnaký ako pri BCI, pričom MAP-ms metóda je naviac rozšírená o status (napr. anomália áno/nie), ktorý je reprezentovaný distribúciou diskrétnej premennej každého merania senzoru.
\end{itemize}
\myFigure{images/2_anomalie_DBN}{Štruktúra dnamickej bayseovej siete. Vektor $X$ reprezentuje spojitú zložku, neznáme alebo tiež nazývané skryté premenné systému a vektory $M$ predstavujú spojité pozorované premenné v čase $t$ \citep{hill2007real}.}{anomalie-dbn}{0.65}{h!}\label{fig:anomalie-dbn}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                     FP                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{FP} -- otazne


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                Zhlukovanie                    %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Zhlukovanie}
Zhlukovanie (angl. clustering) je proces zoskupovania alebo segmentácie objektov z dátovej množiny do zhlukov (angl. cluster) na základe čŕt objektov. Cieľom je vytvoriť zhluky, kde vrámci zhluku budú objekty čo najviac podobné a objekty medzi zhlukmi čo najviac odlišné. Podobne ako pri tradičných metódach pre zhlukovanie, aj metódy pre prúdy dát môžu byť rozdelené do piatich kategórií \citep{nguyen2015survey, aggarwal2014survey}: rozdeľovacie (angl. partitioning) metódy, hierarchické (angl. hierarchical) metódy, metódy založené na hustote (angl. density-based), metódy založené na mriežke (angl. grid-based) a metódy založené na modely (angl. model-based). Algoritmus potrebuje naviac kvantifikovať mieru podobnosti, či vzdialenosti zhlukov. existujú štyri najpoužívanejšie miery pre meranie vzdialenosti: minimálna vzdialenosť (angl. single-linkage), maximálna vzdialenosť (angl. complete-linkage), primerná a stredná vzdialenosť. Zhlukovanie je príklad \textit{učenia bez učiteľa} (angl. unsupervised learning) narozdiel od klasifikácie. Metódy zhlukovania sú často používane počas predspracovania dát napríklad s cieľom redukcie dimenzionality.

\paragraph{Rozdeľovacie metódy} (angl. partitioning methods) rozdeľujú dátovú množinu o $n$ objektoch do $k$ partícií kde každá partícia predstavuje zhluk, pričom platí $k\leq n$. Parameter $k$ je obvykle definovaný používateľom vopred. Najznámejšie tradičné metódy sú $k-means$ a $k-medians$. Existujú implementácie, ktoré upravujú $k-means$ tak aby bola použiteľná na prúdy dát. Všetky tieto implementácie spracujú prúd v malých dávkach, takže nie celkom spôsobom ako je vhodné spracovať prúdy dát \citep{gaber2005mining}.
\par
Jeden z prvých algoritmov, ktoré boli navrhnuté pre prúdy dát je $STREAM$, algoritmus je rozšírením algoritmu $k-medians$. Algoritmus používa techniku rozdeľuj a panuj (angl. divide-and-conquer) s cieľom vytvárania zhlukov inkrementálne. Účelová funkcia algoritmu $STREAM$ je nasledovná:
\begin{align*}
SSQ(M,C) = \sum_{i=1}^{k} \sum_{x_j\Leftarrow c_i} dist(x_j, c_i)
\end{align*}
kde $x$ je dátová vzorka a $c$ reprezentuje zhluk (medián). Funkcia $dist$ je funkcia na meranie vzdialenosti medzi zhlukmi. Algoritmus avšak tiež spracováva dáta v malých dávkach. Na rozhodnutie o veľkosti dávky používa algoritmus $LOCALSEARCH$.

\paragraph{Metódy založené na hustote} vytvárajú profil hustoty dátovej množiny. Tento profil je následne použitý na zhlukovanie. Znamená to teda, že za zhluky považujeme miesta v priestore s vysokou hustotou objektov. Výhodou tejto metódy je, že dokáže objaviť v dátach aj neobvyklé tvary zhlukov. Najznámejšie implementácie sú $DBSCAN$ a $OPTICS$. Toto je všeobecná výhoda metód založených na hustote v porovnaní s rozdeľovacími metódami \citep{han2011data}.
\par
Algoritmus $DenStream$ je rozšírením algoritmu $DBSCAN$, ktorý je vhodný pre zhlukovanie prúdov dát. Tento algoritmus podobne ako $CluStream$ algoritmus navrhnutý Aggarwalom vytvára mikro zhluky na zachytenie informácie o prúde dát. Mikro zhluky sú kontinálne aktualizované a udržiavané v kolekcii mikro zhlukov. Algoritmus používa oslabujúci model na zníženie váh elementov v čase. Vytvárané sú tri typy mikro zhlukov: základný, potenciálny a vyčnievajúci (angl. outlier). Algoritmus potom aplikuje známy $DBSCAN$ algoritmus na vytvorené mikro zhluky, pričom zhluk vzniká z viacerých mikro zhlukov, ktoré su pokope \citep{nguyen2015survey}.
\par
Algoritmus $OPTICS-stream$ je opäť rozšírenie algoritmu $OPTICS$. Podobne ako $DenStream$ vytvára mikro zhluky a aplikuje oslabujúci model. Na vytvorenie finálnych zhlukov rovnako používa pôvodný algoritmus $OPTICS$ z vytvorených mikro zhlukov.

\paragraph{Metódy založené na modeloch} sa snažia optimalizovať podobnosť medzi dátami a statickými modelmi. Známe tradičné metódy sú napríklad $Expectation-Maximization (EM)$ a $Self-Organizing Map (SOM)$. EM je jemná (angl. soft) metóda pre zhlukovanie, SOM je metóda neurónových sietí.
\par
$SWEM$ je algoritmus rozšírený z EM algoritmu. Tento algoritmus používa posuvné okno. Každý mikro komponent je reprezentovaný n-ticou (váha, priemer, kovariančná matica). Najprv je aplikovaný algoritmus EM na získanie konvergujúcich parametrov, následne používa získané parametre ako inicializačné hodnoty pre vytvorenie modelu. SWEM tiež aplikuje oslabujúci model na expiráciu sumarizačných štatistík mikro komponentov \citep{nguyen2015survey}.
\par
Ďalším algoritmom, ktorý vytvára statický model je $GCPSOM$, ktorý je hybridným algoritmom vytvorený z $GSOM$ a $CPSOM$. Algoritmus GSOM je vyvíjajúci sa SOM kde nieje potrebné vopred definovať veľkosť mapy. Mapa GSOM dynamicky rastie podľa hodnoty akumulovaných chýb. CPSOM je bunkový pravdepodobnostný SOM, ktorý používa oslabujúce okno s cieľom redukcie váh neurónov. Teda, GCPSOM má schopnosť dynamického rastu mapy čŕt pre zhlukovanie prúdov dát a udržiavať zhluky tak ako sa prúd vyvíja v čase \citep{nguyen2015survey}.

\paragraph{Hierarchické metódy}
Hierarchické metódy zoskupujú dátové objekty do zhlukov hierarchických stromov. Tieto metódy ďalej rozdeľujeme na aglomeratívne a rozdeľovacie kde dekompozícia hierarchií je formovaná zdola nahovr spájaním alebo zhora nadol rozdeľovaním. Tradičné metódy sú napríklad BIRCH, CURE alebo  ROCK. Metóda CluStream je použiteľná pre prúdu dát pričom rozširuje tradičnú metódu BIRCH. CluStream používa mikro zhluky pre získanie súmárnych informácií o prúde dát. Mikro zhluky sú definované ako rozšírenie funkčných vektorov metódy BIRCH s pridanou časovou zložkou. CluStream si udržuje množinu mikro zhlukov, ak je vytvorený nový mikro zhluk, iný ktorý je outlier je odstránený alebo sú dva podobné mikro zhluky spojené do jedného. Tento algoritmus tiež analyzuje vývoj mikro zhlukov s cieľom odhaliť zmeny v prúde dát \citep{nguyen2015survey}. Algoritmus HPStream je rozšírením algoritmu CluStream, ktorý adresuje problém zhlukovania vysoko dimenzionálných dát. Tento algoritmus sa vysporiadúva s takýmito dátami projekčnou technikou pre výber najlepšieho atribútu pre zhluky. SWClustering je algoritmus, ktorý rieši problém postupnej degradácie algoritmu CluStream, ak beží dlhú dobu. SWClustering vytvára dočasný zhluk čŕt pre posuvné okno. Následne je použitý exponenciálny histogram čŕt zhlukov pre identifikáciu zmien v prúde dát. Tento algoritmus tiež dosahuje lepšiu časovú a pamäťovú efektivitu ako CluStream \citep{han2011data}.

\paragraph{Metódy založené na mriežke}
rozdeľujú priestor na multi-dimenzionálnu mriežku. Mriežka môže obsahovať veľa buniek, pričom každá môže obsahuje svoj podpriestor a naviac si udržuje sumárne informácie o dátach v podpriestore bunky. Zhluky sú potom identifikované hustými oblasťami v okolí buniek. Známy algoritmus pre zhlukovanie prúdov dát podľa mriežky je CellTree \citep{han2011data}. Algoritmus je inicializovaný rozdelením priestoru do množiny rovnako veľkých buniek. CellTree bol rozšírený na lepšiu verziu Cell*Tree, ktorý používa algoritmus BTree na ukladanie informácií o zhlukoch. Cell*Tree tiež aplikuje starnúci model na zvýraznenie poslednej zmeny v prúde dát.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                Klasifikácia                   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Klasifikácia}
\label{ulohy-klasifikacia}
Klasifikácia je proces hľadania všeobecného modelu, ktorý je vytvorený za základe predchádzajúcich pozorovaní. Model je potom použitý na klasifikovanie nových dát. Proces klasifikácie pozostáva z dvoch krokov: \textit{učenie} a \textit{trénovanie}. Počas učenia sa snažíme podľa algoritmu vytvoriť klasifikačný model z trénovacích dát (trénovacia množina). Počas testovania je vytvorený model použitý na klasifikovanie neoznačkovaných dát z testovacej množiny. Existujú rôzne dobre známe metódy pre klasifikáciu: rozhodovacie stromy, naivný Bayes, neurónové siete alebo k-najbližších susedov \citep{nguyen2015survey}. Niektoré z týchto metód sú v upravenej podobe vhodné na klasifikáciu prúdov dát, vybrané z nich sú detailnejšie popísané v tejto podkapitole. 
\par
Problém klasifikácie je zvyčajne formálne definovaný nasledovne: nech $A$ je trénovacia množina o $N$ prvkoch vo forme $(x,y)$ kde $y$ predstavuje skutočnú triedu vzorky a $x$ je vektor s $d$ atribútmi. Každý atribút môže nadobúdať numerické alebo kategorické hodnoty. Cieľom je vytvoriť na základe trénovacej množiny model resp. funkciu $y=f(x)$, ktorá bude predikovať triedu $y$ pre nové vzorky $x$ s vysokou presnosťou \citep{domingos2000mining}. 
\par
Väčšsina klasifikačných metód používa vzorkovanie s cieľom zvýšiť presnoť klasifikátora \citep{aggarwal2014survey, nguyen2015survey}. Často je použitá technika zásobníkového vzorkovania (angl. Reservoir sampling), ktorá umožňuje zvýšiť efektivitu klasifikátora. Myšlienka je v udržiavaní malej kontinuálnej trénovacej vzorke dát. Klasifikačný algoritmus je potom kedykoľvek aplikovaný na vzorku s cieľom vytvorenia modelu \citep{aggarwal2014survey}. Klasifikácia je problém \textit{učenia s učiteľom} (angl. supervised learning) čo znamená, že pri trénovaní sú známe skutočné triedy dátových vzoriek.

% Multi naive bayes
\paragraph{Multinomiálny naivný Bayes} je klasifikátor najčastejšie používaný na klasifikáciu dokumentov, ktorý obvykle poskytuje dobré výsledky aj čo sa týka presnosti výsledku aj rýchlosti. Túto metódu je jednoduché aplikovať v kontexte prúdu dát \citep{bifet2010sentiment}. Multinomiálny naivný Bayes sa pozerá na dokument ako na zhluk slov. Pre každú triedu $c$, $P(w|c)$, pravdepodobnosť, že slovo $w$ patrí do tejto triedy je odhadovaná z trénovacích dát jednoducho vypočítaním relatívnej početnosti každého slova v trénovacej sade pre danú triedu. Klasifikátor potrebuje naviac nepodmienenú pravdepodobnosť $P(c)$. Za predpokladu, že $\displaystyle n_{wd}$ je počet výskytov slova $w$ v dokumente $d$, pravdepodobnosť triedy $c$ z testovacieho dokumentu je nasledovaná: \newline
\begin{align*}
P(c|d) = \frac{P(c)\prod _{w \in d} P(w|c)^{n_{wd}}} {P(d)}
\end{align*}
Kde $P(d)$ je normalizačný faktor. Aby sme sa vyhli problému kedy sa trieda nevyskytuje v datasete ani jeden krát, je bežné použitie Laplacovej korekcie a nahradenie nulových početností jednotkou, resp. inicializovať početnosť každej triedy na 1 namiesto 0.

% SGD a SVM
\paragraph{Stochastický gradientný zostup a metóda podporných strojov} (angl. Stochastic Gradient Descent, SGD). Bifet a Frank v ich práci použili implementáciu tzv. vanilla stochastický gradientný zostup s pevnou rýchlosťou učenia, optimalizujúc stratu s $L_2$ penalizáciou. $L_2$ penalizácia je často používaná pri podporných vektorových strojoch (angl. Support Vector Machines, ďalej len SVM). Lineárny stroj, ktorý je často aplikovaný na problémy klasifikácie dokumentov, optimalizujeme funkciu straty nasledovne:
\begin{align*}
\frac{\lambda }{2}\left \| w \right \|^{2}+\sum [1-(yxw + b)]_{+}
\end{align*}
kde $w$ je váhovaný vektor, $b$ je sklon, $\lambda$ regulačný parameter a označenie triedy $y$ je z intervalu $\{+1, -1\}$.
\par
SVM ukazujú dobré výsledky v mnohých úlohách a problémoch strojového učenia, ak je táto metóda použitá na statické datasety. Avšak, ich použitie v neupravenej forme je problematické na prúdy dát kvoli ich časovej zložitosti $O(N^3)$ a pamäťovej zložitosti $O(N^2)$, kde $N$ je počet dátových vzoriek \citep{nguyen2015survey}. Tsang a spol. navrhli metódu jadrových vektorových strojov (angl. Core Vector Machine, CVM), ktorá používa uzavretie minimálnou guľou (angl. Minimum Enclosing Ball - MEB,v 2D priestore tiež známe ako problém pokrytia minimálnou kružicou) na redukciu časovej a pamäťovej zložitosti. Metóda StreamsSVM je rozšírením CVM a bola navrhnutá s ohľadom na spracovanie prúdov dát \citep{rai2009streamed}. StreamsSVM používa flexibilný rádius MEB, ktorý sa mení podľa nových vzoriek z prúdu dát. Výsledky sa blížia k výsledkom z optimálneho algoritmu, avšak problém tejto metódy je neschopnosť vysporiadať sa so zmenami (angl. concept-drift) v prúde dát.


% HFDT, VFDT, CVFDT
\paragraph{Rozhodovacie stromy} (angl. Decision trees) sú častou metódou používanou na klasikáciu. Modely rozhodovacích stromov dosahujú v praxi vysokú presnosť zatiaľ čo model je jednoduchý na vysvetlenie \citep{jin2003efficient, hulten2001mining, domingos2000mining, aggarwal2014survey}. Existuje niekoľko škálovateľných metód pre rozhodovacie stromy, napríklad SLIQ, RainForest alebo BOAT \citep{aggarwal2014survey}. Napriek tomu, že sú tieto metódy škálovateľné, nie sú navrhnuté a ani vhodné na použitie pre prúdy dát. Neskôr boli navrhnuté rodiny algoritmov ako ID3, ktoré boli síce navrhnuté aj s ohľadom na prúdy dát, ale problém je že neboli tak aby  zohľadnili zmeny v modely. Rozhodovacie stromy predikujú resp. klasifikujú novú vzorku do triedy $y$ podľa výsledkov testov v rozhodovacích uzloch a triedy v liste stromu do ktorého spadne vzorka.
\par
Jedna z prvých state-of-the-art metód, ktorá bola navrhnutá špecificky pre prúdy dát je \textit{Hoeffdingov strom} (angl. Hoeffding tree, ďalej len HT).  Je to najznámejšia implementácia rozhodovacích stromov v použití prúdového spracovania \citep{domingos2000mining, aggarwal2014survey, nguyen2015survey}. HT vyžaduje prečítanie každej novej vzorky z prúdu najviac jeden krát. Táto vlastnosť umožňuje použitie HT nad prúdmi dát s akceptovateľnou časovou a pamäťovou zložitosťou. Prečítané vzorky nieje potrebné ukladať na disk. HT využíva fakt, že malá vzorka dát je často postačujúca na výber optimálneho rozdelovacieho atribútu. Toto tvrdenie je matematicky podporené Hoeffdingovou mierou alebo súčtovou Chernoffovou mierou \citep{domingos2000mining, han2011data}. Rutkowski a spol. tvrdia, že stromy, ktoré používaju Hoeffdingovu mieru v skutočnosti používajú McDiarmidovu mieru a mali by sa tieto stromy nazývať McDiarmdove \citep{rutkowski2013decision}. HT dosahujú sa vo všeobecnosti asymptoticky približujú kvalitou k tým, ktoré sú vytvorené metódou pre dávkové spracovanie \citep{hall2009weka}.
\par
Predpokladajme $N$ nezávislých pozorovaní náhodnej premennej $r \in R$ kde $r$ je metrika výberu atribútu. V prípade HT to môže byť napríklad informačný zisk (angl. information gain). Ak vypočítame priemer vzorky $\overline{r}$ potom Hoeffdingova miera hovorí, že skutočný priemer $r$ je aspoň $\overline{r}-\epsilon$ s pravdepodobnosťou $1-\delta$. Pričom $\delta$ je parameter definovaný používateľom a 
\begin{align*}
\epsilon = \sqrt{ \frac{R^2ln(1/\delta)} {2n} }
\end{align*}
HT algoritmus používa Hoeffdingovu mieru na výber najmenšieho čísla $N$ - počet vzoriek potrebných v uzle na výber rozdeľovacieho atribútu. Presnejšie, v každom uzle stromu maximalizujeme $G(A_j)$ kde funkcia G predstavuje metriku kvality atribútu $A_j$ vzorky, napríklad informačný zisk. Cieľom je nájsť najmeší počet vzoriek $N$ tak aby bola splnená Hoeffdingova miera. Nech $G(A_a)$ predstavuje atribút s najvyššou hodnotou $G$ a nech $G(A_b)$ je druhý najlepší atribút. Potom ak $G(A_a) - G(A_b) > \epsilon$ môžme s istotou tvrdiť, že rozdiel je väčší ako nula. Následne vyberieme $A_a$ ako najlepší rozdeľovací atribút v danom uzle s istotu $1-\delta$. Jediné dáta, ktoré si potrebuje HT algoritmus ukladať sú postačujúce štatistiky potrebné pre rozhodovanie a výpočet Hoeffdingovej miery, sú to počítadlá $n_ijk$ pre hodnotu $v_j$ atribútu $A_i$ z triedy $y_k$. Slabá stránka tohto algoritmu je v tom, že očakáva na vstupe prúd, ktorý neobsahuje zmeny (angl. concept-drift \citep{domingos2000mining}.
\par %TODO: pridat HFDT pseudokod


Existuje niekoľko modifikácií HT algoritmu. Tá najzákladnejšia je jeho rýchla verzia (angl. Very Fast Decision Trees, VFDT) \citep{domingos2000mining}. Modifkácia HT algoritmu, ktorá sa vie vysporiadať so zmenami v prúde sa nazýva \textit{Rýchly algoritmus pre rozhodovacie stromy adaptujúci sa na zmeny} (angl. Concept-adapting Very Fast Decision Tree, CVFDT \citep{hulten2001mining}. CVFDT používa posuvné okno, pričom nevytvára pri detekovanej zmene nový model. Namiesto toho aktualizuje postačujúce štatistiky v uzloch inkrementovaním počítadiel nových vzoriek a dekrementovaním počítadiel vzoriek, ktoré vypadli z posuvného okna. Teda, ak je v prúde dát zmena, niektoré uzly stromu nemusia viac spĺňať Hoeffdingovu mieru. Keď nastane takáto situácia, alternujúci podstrom začne narastať v uzle, ktorý nesplnil Hoeffdingovu mieru. s novými vzorkami bude alternujúci podstrom rásť, zatiaľ bez toho aby bol použitý v modeli na klasifikáciu. V momente keď sa stane alternujúci podstrom presnejší ako aktuálny, starý podstrom je nahradený alternujúcim podstromom. V algoritme je možné nastaviť hraničnú hodnotu minimálneho počtu vzoriek, ktoré musí alternujúci podstrom spracovať predtým než sa pokusí nahradiť pôvodný \citep{hulten2001mining}.
\par
Ďalšou modifikáciou HT je \textit{Adaptívny sa Hoeffdingov strom} (angl. Hoeffding Adaptive Tree) predstavený Bifetom a Gavaladom v 2009. Princíp je veľmi podobný ako CVFDT, ale myšlienka je minimalizovať počet parametrov, ktoré musí používateľ nastaviť (napr. veľkosť okna $W$ je požadovaný parameter CVFDT). Adaptívny HT používa rôzne 	kritéria pre odhad potrebnej veľkosti okna automaticky, napríklad algoritmus \textit{ADWIN}. S použitím tohto kritéria používateľ nemusí zadať parameter veľkosti okna čo je obrovký prínos, pretože potrebná veľkosť sa môže meniť spolu so zmenami v prúde dát. Adaptívny HT s kritériom ADWIN dosahuje v niektorých prípadoch lepšie výsledky ako CVFDT \citep{bifet2009adaptive}.
\par
Existujú aj ďalšie odlišné metódy rozhodovacích stromov, ktoré aplikujú súborové (angl. ensemble) metódy, rôzne klasifikátory v listoch ako napríklad naivný Bayes, či stromy založené na fuzzy logike \citep{aggarwal2014survey}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                Zhodnotenie                    %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Zhodnotenie}
Existuje mnoho problémov analýzy prúdu dát. Väčšina týchto problémov je odvodených od tých z tradičného dávkového spracovania dát. Vďaka tomu tiež väčšina algoritmov na riešenie týchto úloh a problémov rozširuje tradičné algoritmy. Ako napríklad algoritmus rozhodovacích stromov pre klasifikáciu, ktorý používa Hoeffdingovu mieru pre určenie istoty výberu najlepšie atribútu pre vytvorenie rozhodovacieho uzla. Niektoré metódy do istej miery riešia problém zmien v prúde dát, avšak často len pomocou staticky nastavených parametrov používateľom. Tento prístup zlyháva, ak sa menia aj samotné zmeny, čo je častý prípad prúdov reálneho sveta.









